{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import datetime as dt\n",
    "\n",
    "home = pl.Path(r'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\fino2py\\data')\n",
    "p1 = pl.Path(r'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\fino2py\\data\\Participant 1_2022-10-27_09.07.37')\n",
    "p2 = pl.Path(r'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\fino2py\\data\\Partcipant 59_2022-11-21_10.37.29')\n",
    "time_stamps = pd.read_excel(r'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\fino2py\\data\\Timesheets (1).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_seconds_to_time(time_str):\n",
    "    '''This function adds seconds to the time string for incase the time string is missing seconds'''\n",
    "    if len(time_str) == 5:\n",
    "        time_str += \":00\"\n",
    "    return time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamps.iloc[:, 1:] = time_stamps.iloc[:, 1:].applymap(lambda x: add_seconds_to_time(x) if isinstance(x, str) else x)\n",
    "time_stamps.columns = [i.strip() for i in time_stamps.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamps.head().to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some instances of 'Participant' are misspelled as 'Partcipant' in the file names. This is a quick fix to correct this.\n",
    "# Define the directory path where you want to replace the string\n",
    "directory = pl.Path(r'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\fino2py\\data')\n",
    "\n",
    "# Define the old string and the new string\n",
    "old_str = 'Partcipant'\n",
    "new_str = 'Participant'\n",
    "\n",
    "# Walk through all directories and files within the specified directory\n",
    "for path in directory.glob('**/*'):\n",
    "    if old_str in path.name:\n",
    "        # Replace the old string with the new string in the file or directory name\n",
    "        new_name = path.name.replace(old_str, new_str)\n",
    "        if new_name != path.name:\n",
    "            # If the name has changed, rename the file or directory\n",
    "            path.rename(path.with_name(new_name))\n",
    "            print(f'Renamed {path.name} to {new_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This imports the raw data from the finometer and then calculates the average of each measure over the selected time period\n",
    "# the default time period is 1 minute, but if you want to change this you can change the interval variable (e.g. interval = '30s' for 30 seconds)\n",
    "\n",
    "def import_finometer_intervals(folder_path, interval = '1T', save_csv=False):\n",
    "    '''This function imports the finometer data and then calculates the average of each measure over the selected time period'''\n",
    "\n",
    "    if not isinstance(folder_path, pl.Path):#check if folder_path is a pathlib.Path object\n",
    "        raise TypeError('folder_path must be a pathlib.Path object')\n",
    "    elif not folder_path.exists(): #  and if it exists\n",
    "        raise ValueError('folder_path does not exist')\n",
    "    elif not folder_path.is_dir(): #  and is a directory \n",
    "        raise ValueError('folder_path is not a directory')\n",
    "    elif len([x for x in folder_path.iterdir() if x.suffix == '.txt']) != 1:  # and if there is only one .txt file in the folder\n",
    "        raise ValueError('''More than one .txt file found in folder, please ensure only one .txt file is present in the folder''')\n",
    "    else:\n",
    "        file = [x for x in folder_path.iterdir() if x.suffix == '.txt'][0]\n",
    "    # read in the data from the .txt file\n",
    "        df = pd.read_csv(\n",
    "            file,\n",
    "            sep=';',\n",
    "            header=0,\n",
    "            skiprows=8, # skip the first 8 rows\n",
    "            skipfooter=1,\n",
    "            engine='python',\n",
    "            )\n",
    "\n",
    "        # Drop the unnamed column at position 13\n",
    "        df = df.drop(df.columns[13], axis=1)\n",
    "\n",
    "        # set the 'Time (s)' column to a datetime object\n",
    "        df['Time (s)'] = pd.to_datetime(df['Time (s)'], format='%H:%M:%S.%f')\n",
    "        # drop the year from the datetime object\n",
    "        # df['Time (s)'] = df['Time (s)'].dt.strftime('%H:%M:%S.%f')\n",
    "\n",
    "        # set the 'Time (s)' column as the index\n",
    "        df = df.set_index('Time (s)')\n",
    "\n",
    "        # create the average of each measure over the selected time period\n",
    "        df_munutes = df.resample(f'{interval}').mean()\n",
    "\n",
    "        if save_csv: #if you want to save the csv file (which may be useful if you want to use the data in other ways)\n",
    "            df_munutes.to_csv(folder_path / f\"imported data for {file.stem.split('_')[0]}.csv\", index=True)\n",
    "            print(f\"CSV saved for {file.stem.split('_')[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "        return df_munutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin.omalley\\AppData\\Local\\Temp\\ipykernel_18536\\2086346037.py:39: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_munutes = df.resample(f'{interval}').mean()\n"
     ]
    }
   ],
   "source": [
    "a = import_finometer_intervals(p1, interval = '1T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| Time (s)            |   Systolic Pressure (mmHg) |   Diastolic Pressure (mmHg) |   Mean Pressure (mmHg) |   Heart rate (bpm) |   Stroke Volume (ml) |   Left Ventricular Ejection Time (ms) |   Pulse Interval (ms) |   Maximum Slope (mmHg/s) |   Cardiac Output (l/min) |   Total Peripheral Resistance Medical Unit (mmHg.min/l) |   Total Peripheral Resistance CGS (dyn.s/cm5) |\\n|:--------------------|---------------------------:|----------------------------:|-----------------------:|-------------------:|---------------------:|--------------------------------------:|----------------------:|-------------------------:|-------------------------:|--------------------------------------------------------:|----------------------------------------------:|\\n| 1900-01-01 09:07:00 |                    74.4815 |                     51.6667 |                 62     |            93.5556 |              16.0926 |                               135.926 |               642.778 |                  478.407 |                  1.54074 |                                                 1.17244 |                                       1563.19 |\\n| 1900-01-01 09:08:00 |                   153.928  |                    110.402  |                131.505 |            97.6495 |              31.3577 |                               272.216 |               618.041 |                 1000.09  |                  3.05876 |                                                 2.60363 |                                       3471.54 |\\n| 1900-01-01 09:09:00 |                   154.237  |                    111.132  |                130.961 |            94.0395 |              30.8026 |                               274.737 |               679.013 |                 1006.66  |                  2.91447 |                                                 2.91334 |                                       3884.5  |\\n| 1900-01-01 09:10:00 |                   139.914  |                     96      |                114.034 |            88.7931 |              37.5207 |                               315.431 |               730.172 |                  980     |                  3.2431  |                                                 2.40909 |                                       3212.12 |\\n| 1900-01-01 09:11:00 |                   152.784  |                    123.433  |                138.031 |            97.5876 |              18.6887 |                               228.247 |               616.649 |                  592.515 |                  1.80825 |                                                 4.8869  |                                       6515.86 |'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head().to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates the 1 minute intervals for each participant\n",
    "# it saves a file for each person in their folder\n",
    "[import_finometer_intervals(x, save_csv=True) for x in home.iterdir() if x.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_finometer_protocol_times(times_file_path, seconds = False):\n",
    "    '''This function imports the protocol times from the .csv file and returns a dataframe with the protocol times for each participant\n",
    "    \n",
    "    file_path: pathlib.Path object\n",
    "        The path to the .csv file containing the protocol times\n",
    "    save_csv: boolean (optional)\n",
    "        If True, the imported data will be saved as a .csv file in the same folder as the .csv file, this is not alway needed and should be used sparingly'''\n",
    "\n",
    "\n",
    "    def add_seconds_to_time(time_str):\n",
    "        '''This function adds seconds to the time string for incase the time string is missing seconds'''\n",
    "        if len(time_str) == 5:\n",
    "            time_str += \":00\"\n",
    "        return time_str\n",
    "    \n",
    "    def remove_seconds_from_time(time_str):\n",
    "        '''This function removes seconds from the time string'''\n",
    "        return time_str[:-3]\n",
    "    \n",
    "   \n",
    "\n",
    "    if not isinstance(times_file_path, pl.Path):#check if folder_path is a pathlib.Path object\n",
    "        raise TypeError('file_path must be a pathlib.Path object')\n",
    "    elif not times_file_path.exists(): #  and if it exists\n",
    "        raise ValueError('file_path does not exist')\n",
    "    elif not times_file_path.is_file(): #  and is a file \n",
    "        raise ValueError('file_path is not a file')\n",
    "    elif times_file_path.suffix != '.csv': #  and is a csv file\n",
    "        raise ValueError('file_path is not an csv file')\n",
    "    else:\n",
    "        df = pd.read_csv(times_file_path, delimiter= ',')\n",
    "        df.columns = [col.strip() for col in df.columns]\n",
    "        cols_to_keep = ['Participant ID', 'Start of Baseline', 'End of Baseline', 'Start of Task 1', 'End of Task 1', 'Start of Recovery Period', 'End of Recovery Period']\n",
    "        df = df[cols_to_keep].applymap(lambda x: str(x).strip('\"') if isinstance(x, str) else x)\n",
    "\n",
    "        if seconds:\n",
    "            df = df.applymap(lambda x: add_seconds_to_time(x) if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df = df.applymap(lambda x: remove_seconds_from_time(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_finometer_demographics(file_path):\n",
    "    '''\n",
    "    A function to import the demographic data from a smartmedical/finopress\n",
    "    finometer .txt file\n",
    "    \n",
    "    file_path =  should be a path to a .txt file, this can be string but should preferably be a pathlib object to allow for use on multiple operating\n",
    "    systems\n",
    "    '''\n",
    "\n",
    "    if not isinstance(file_path, pl.PurePath):\n",
    "        try:\n",
    "            file_path = pl.Path(file_path)\n",
    "        except TypeError:\n",
    "            raise TypeError(\"\"\"The 'file_path' must be a path object or a string that can be converted to a path object. Remember 'raw strings on windows devices\"\"\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data=[]\n",
    "            for line in file:\n",
    "                if line.startswith('Identification'):\n",
    "                    data.append(line.strip().split(';'))\n",
    "                    next_line = next(file).strip()\n",
    "                    if next_line:\n",
    "                        data.append(next_line.split(';'))\n",
    "                    break\n",
    "            \n",
    "            if len(data) < 2:\n",
    "                raise ValueError(\"File doesn't contain expected data\")\n",
    "            \n",
    "\n",
    "            df = pd.DataFrame(data, columns= ['Participant ID', 'ID 2', 'Age (yrs)', 'Height (cm)', 'Weight (kg)', 'Gender', 'Procedure', 'Model number'])\n",
    "            df = df.drop(0)\n",
    "            df = df.drop('ID 2', axis = 1)\n",
    "\n",
    "\n",
    "            return(df)      \n",
    "                        \n",
    "\n",
    "    except (TypeError, ValueError, FileNotFoundError) as err:\n",
    "        print(str(file_path), type(err), err)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([import_finometer_demographics(f) for f in p1.parent.glob(\"**/*\") if f.suffix == '.txt'], axis = 0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_protocol_averages_feb_23(f, t1 = None, t2 = None, t3 = None, t4 = None, t5 = None, t6= None):\n",
    "    '''A function that imports the averaged finomter files (which have already been processed from the raw data)\n",
    "    to produce averages for each section of the experiment protocol'''\n",
    "\n",
    "    \n",
    "    if not isinstance(f, pl.Path):#check if folder_path is a pathlib.Path object\n",
    "        raise TypeError('file_path must be a pathlib.Path object')\n",
    "    elif not f.exists(): #  and if it exists\n",
    "        raise ValueError('file_path does not exist')\n",
    "    else:\n",
    "    # check if the file is a csv or xlsx file\n",
    "        if f.suffix == '.csv':\n",
    "            try:\n",
    "                intervals = pd.read_csv(f, index_col=0, parse_dates=True)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"File {f} is empty\")# might need to fix this but its a start\n",
    "        elif f.suffix == '.xlsx':\n",
    "            try:\n",
    "                intervals = pd.read_excel(f, index_col=0, parse_dates=True)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"File {f} is empty\")# might need to fix this but its a start\n",
    "        else:\n",
    "            raise ValueError(\"File must be a Path object for a .csv or .xlsx file\")\n",
    "\n",
    "\n",
    "    intervals.index = pd.to_datetime(intervals.index).strftime('%H:%M:%S')\n",
    "    intervals = intervals.replace('--', np.nan) #getting rid of blank values (converting them to 'nan' instead of just '--')\n",
    "    intervals = intervals.dropna(how='all') #getting rid of rows that are completely blank\n",
    "\n",
    "    def create_protocol_part_df(frame, start, end, tag, filename):\n",
    "        '''A function that creates a dataframe representing a time period within a particular experimental protocol from a given DataFrame.\n",
    "        Takes a DataFrame, start and end times for the portion of the experimental protocol.\n",
    "        Returns a DataFrame with the mean values of the given columns during that portion of the study.'''\n",
    "        \n",
    "        period = frame.loc[start:end].dropna().T\n",
    "        period['Average'] = period.mean(axis=1)\n",
    "        b = pd.DataFrame(period['Average']).T\n",
    "        b.columns = [f'{i}_{tag}' for i in b.columns]\n",
    "        b['Participant ID'] = f'{filename}'\n",
    "        # b = b.set_index('Participant ID')\n",
    "        \n",
    "        return b\n",
    "\n",
    "    #creating the baseline dataframe\n",
    "    baseline = create_protocol_part_df(intervals, t1, t2, 'bl', f.parent.stem.split('_')[0])\n",
    "\n",
    "    # #creating the baseline dataframe\n",
    "    # baseline = df.loc[t1:t2].dropna().T\n",
    "    # baseline['Average'] = baseline.mean(axis = 1)\n",
    "    # b =  pd.DataFrame(baseline['Average']).T\n",
    "    # b.columns = [f'{i}_bl' for i in b.columns]\n",
    "    # b['ID'] = f'{f.name}'\n",
    "\n",
    "\n",
    "    # #creating the instruction dataframe\n",
    "    # inst = df.loc[t3:t4].dropna().T\n",
    "    # inst['Average'] = inst.mean(axis = 1)\n",
    "    # ins =  pd.DataFrame(inst['Average']).T\n",
    "    # ins.columns = [f'{i}_ins' for i in ins.columns]\n",
    "    # ins['ID'] = f'{f.name}'\n",
    "    \n",
    "    # #creating the task dataframe\n",
    "    # task = df.loc[t5:t6].dropna().T\n",
    "    # task['Average'] = task.mean(axis = 1)\n",
    "    # t =  pd.DataFrame(task['Average']).T\n",
    "    # t.columns = [f'{i}_task' for i in t.columns]\n",
    "    # t['ID'] = f'{f.name}'\n",
    "\n",
    "    # #creating the recovery dataframe\n",
    "    # rec = df.loc[t7:t8].dropna().T\n",
    "    # rec['Average'] = rec.mean(axis = 1)\n",
    "    # r =  pd.DataFrame(rec['Average']).T\n",
    "    # r.columns = [f'{i}_rec' for i in r.columns]\n",
    "    # r['ID'] = f'{f.name}'\n",
    "    \n",
    "\n",
    "    # # creating a dataframe from the smaller dataframes\n",
    "    # data_merge = reduce(lambda left, right:     # Merge three pandas DataFrames\n",
    "    #                  pd.merge(left , right,\n",
    "    #                           on = [\"ID\"],\n",
    "    #                           how = \"outer\"),\n",
    "    #                  [b,ins,t,r])\n",
    "    # data_merge.set_index('ID', inplace=True) # setting the 'ID' column as the index of the new merged dataframe\n",
    "    \n",
    "\n",
    "    \n",
    "    return baseline # passing the new dataframe back to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = import_protocol_averages_feb_23(pl.Path(r'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\fino2py\\data\\Participant 1_2022-10-27_09.07.37\\imported data for Participant 1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Systolic Pressure (mmHg)_bl</th>\n",
       "      <th>Diastolic Pressure (mmHg)_bl</th>\n",
       "      <th>Mean Pressure (mmHg)_bl</th>\n",
       "      <th>Heart rate (bpm)_bl</th>\n",
       "      <th>Stroke Volume (ml)_bl</th>\n",
       "      <th>Left Ventricular Ejection Time (ms)_bl</th>\n",
       "      <th>Pulse Interval (ms)_bl</th>\n",
       "      <th>Maximum Slope (mmHg/s)_bl</th>\n",
       "      <th>Cardiac Output (l/min)_bl</th>\n",
       "      <th>Total Peripheral Resistance Medical Unit (mmHg.min/l)_bl</th>\n",
       "      <th>Total Peripheral Resistance CGS (dyn.s/cm5)_bl</th>\n",
       "      <th>Participant ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>199.787891</td>\n",
       "      <td>155.626108</td>\n",
       "      <td>173.729357</td>\n",
       "      <td>89.63786</td>\n",
       "      <td>17.403839</td>\n",
       "      <td>242.961308</td>\n",
       "      <td>680.683736</td>\n",
       "      <td>1110.357707</td>\n",
       "      <td>1.559994</td>\n",
       "      <td>7.332134</td>\n",
       "      <td>9776.167137</td>\n",
       "      <td>Participant 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Systolic Pressure (mmHg)_bl  Diastolic Pressure (mmHg)_bl  \\\n",
       "Average                   199.787891                    155.626108   \n",
       "\n",
       "         Mean Pressure (mmHg)_bl  Heart rate (bpm)_bl  Stroke Volume (ml)_bl  \\\n",
       "Average               173.729357             89.63786              17.403839   \n",
       "\n",
       "         Left Ventricular Ejection Time (ms)_bl  Pulse Interval (ms)_bl  \\\n",
       "Average                              242.961308              680.683736   \n",
       "\n",
       "         Maximum Slope (mmHg/s)_bl  Cardiac Output (l/min)_bl  \\\n",
       "Average                1110.357707                   1.559994   \n",
       "\n",
       "         Total Peripheral Resistance Medical Unit (mmHg.min/l)_bl  \\\n",
       "Average                                           7.332134          \n",
       "\n",
       "         Total Peripheral Resistance CGS (dyn.s/cm5)_bl Participant ID  \n",
       "Average                                     9776.167137  Participant 1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the first finometer function, but the use case has somehwat changed, I'm going to keep it here for now, but it will be removed in the future\n",
    "#The function needs to be about reshaping the data, which probably needs to be applied to the data after `import_finomteter_intervals` has been run\n",
    " \n",
    "\n",
    "def import_finometer_txt(folder_path, save_csv=False, zero_time=False):\n",
    "    \"\"\"\n",
    "    Imports raw data from the finopress finometer .txt file and returns a pandas dataframe, resahped from tall to wide format.\n",
    "    The function will only work if there is only one .txt file in the folder.\n",
    "    i: pathlib.Path object\n",
    "    save_csv: boolean, if True, will save a csv file of the imported data into the participant's folder\n",
    "    zero_time: boolean, if True, will convert the time column to a timedelta object and set the first timepoint to 0\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    if not isinstance(folder_path, pl.Path):#check if folder_path is a pathlib.Path object\n",
    "        raise TypeError('folder_path must be a pathlib.Path object')\n",
    "    elif not folder_path.exists(): #  and if it exists\n",
    "        raise ValueError('folder_path does not exist')\n",
    "    elif not folder_path.is_dir(): #  and is a directory \n",
    "        raise ValueError('folder_path is not a directory')\n",
    "    elif len([x for x in folder_path.iterdir() if x.suffix == '.txt']) != 1:  # and if there is only one .txt file in the folder\n",
    "        raise ValueError('''More than one .txt file found in folder, please ensure only one .txt file is present in the folder''')\n",
    "    else:\n",
    "        file = [x for x in folder_path.iterdir() if x.suffix == '.txt'][0]\n",
    "    # read in the data from the .txt file\n",
    "        df = pd.read_csv(\n",
    "            file,\n",
    "            sep=';',\n",
    "            header=0,\n",
    "            skiprows=8, # skip the first 8 rows\n",
    "            skipfooter=1,\n",
    "            engine='python',\n",
    "            )\n",
    "\n",
    "        # Drop the unnamed column at position 13\n",
    "        df = df.drop(df.columns[13], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        # set the 'Time (s)' column to a datetime object        \n",
    "        df['Time (s)'] = pd.to_datetime(df['Time (s)'], format='%H:%M:%S.%f')\n",
    "        # drop the year from the datetime object\n",
    "        df['Time (s)'] = df['Time (s)'].dt.strftime('%H:%M:%S.%f')\n",
    "\n",
    "        # check if the user wants to set the first timepoint to 0\n",
    "        if zero_time:\n",
    "            min_time = df['Time (s)'].min()\n",
    "            df['Time Since 0'] = df['Time (s)'] - min_time\n",
    "            df['Time Since 0'] = df['Time Since 0'].dt.total_seconds()\n",
    "            df['']\n",
    "        else:\n",
    "            df = df.set_index('Time (s)')\n",
    "\n",
    "        alligned = df.groupby(df.index)[df.columns[1:]].max().stack().to_frame().T\n",
    "        alligned.index = [file.stem.split('_')[0]]\n",
    "\n",
    "        if save_csv:\n",
    "            alligned.to_csv(folder_path / f\"imported data for {file.stem.split('_')[0]}.csv\")\n",
    "            print(f\"CSV saved for {file.stem.split('_')[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "        return alligned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311_fin2py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec5b7a3e9aee15186bee3b253678b1b296699de82fe9428094fdd79924013faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
